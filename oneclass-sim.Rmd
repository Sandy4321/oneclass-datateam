---
title: "Simulation study exploring changes in kernel, nu, gamma, degree"
output:
  html_document:
    toc: true
    number_sections: true
    theme: cosmo
    toc_depth: 2
---




```{r lib, echo = F, warning = F, message = F}
# source class1 function
source("oneclass-pred.R")


# Load libraries
library(e1071)
library(dplyr)
library(mvtnorm)
library(ggplot2)
library(RColorBrewer)
library(knitr)


opts_chunk$set(message = F, fig.align = "center", warning = F, echo = F, fig.width = 20, fig.height = 40)

```




```{r sim1}
# Simulate data
N <- 500
mean1 <- 1 * c(10, 10)
sig2 <- 1
c1 <- 0.6
corr <- cbind(c(1, c1), c(c1, 1))
sigma1 <- sig2 * corr
set.seed(10)
x <- rmvnorm(N, mean = mean1, sigma = sigma1)
```


# Plot of the simulated two dimensional data- this has two features

```{r plot1}
# Plot data
plot(x[, 1], x[, 2], xlim = c(-1, 15), ylim = c(-1, 15))

```





```{r simfun}
#' function to obtain one-class results for different hyperparameters
#' @param x features (n obs X n features)
#' @param k1 kernel
#' @param gam1 gamma
#' @param nu1 nu
#' @param deg1 degree
simfun <- function(x, k1, gam1, nu1, deg1, co1) {
	types <- "0"
	svm_modelN <- list()
	for(i in 1 : length(gam1)) {
		svm_modelN[[i]] <- list()
		for(j in 1 : length(nu1)) {
			svm_modelN[[i]][[j]] <- list()
			for(k in 1 : length(deg1)) {
				
				svm_modelN[[i]][[j]][[k]] <- list()
				for(c1 in 1 : length(co1)) {
				type1 <- paste0("Gam=", gam1[i], ", Nu=", nu1[j],  ", Cost=", co1[c1]) 
			        types <- c(types, rep(type1, nrow(x)))	
				svm_modelN[[i]][[j]][[k]][[c1]] <- svm(x, kernel = k1, scale = F, cost = co1[c1],
					type = "one-classification", gamma = gam1[i], nu = nu1[j], degree = deg1[k])
				}
			}
		}
	}
	types <- types[-1]
	list(svmm = svm_modelN, types = types)
}


```



```{r fun2}


#' Function to display all one-class results
#' @param x features (n obs X n features)
#' @param svm_model_out results from simfun 
plotfun <- function(x, svm_model_out) {
	svm_modelN <- svm_model_out$svmm
	types <- svm_model_out$types
	# For each predicted plot
	pred2 <- TRUE
	xdat <- x
	l <- 1
	for(i in 1 : length(svm_modelN)) {
		for(j in 1 : length(svm_modelN[[i]])) {
			for(k in 1 : length(svm_modelN[[i]][[j]])) {
				for(c1 in 1 : length(svm_modelN[[i]][[j]][[k]])) {

					if(l > 1) {
						xdat <- rbind(xdat, x)
					}
					pred2 <- c(pred2, predict(svm_modelN[[i]][[j]][[k]][[c1]]))
					l <- l + 1
				}
			}
		}
	}
	pred2 <- pred2[-1]
	# Specify colors based on predictions
	cols <- ifelse(pred2, "Normal", "Anomalous")
	cols2 <- brewer.pal(3, "Dark2")[1 : 2]
	# Plot points by prediction
	s1 <- sign(mean1[1])
	lims <- sort(c(mean1[1] + s1 * 5, s1), decreasing = F)


	newdat <- data.frame(xdat, cols, types)
	colnames(newdat) <- c("x1", "x2", "pred", "types")

	ggplot(newdat, aes(x = x1, y = x2, col = pred)) + 
		geom_point(size = 5) + 
		facet_wrap( ~ types, ncol = 5) +
		theme_bw() +
		theme(text = element_text(size = 20)) +

		scale_colour_manual(name = "", values = cols2)
}

```

# Linear kernel


```{r lin}
k1 <- "linear"
deg1 <- c(3)
nu1 <- c(0.01, 0.1, 0.2, 0.4, 0.8)
gam1 <- c(0.01, 0.1, 1, 5)
co1 <- c(0.01, 1, 100, 500, 1000)
simlin <- simfun(x, k1, gam1, nu1, deg1, co1) 
plotfun(x, simlin)
```




# Polynomial kernel


```{r poly, fig.height = 30, eval = F}
k1 <- "polynomial"
deg1 <- seq(3, 7)
nu1 <- c(0.1, 0.2, 0.4)
simpoly <- simfun(x, k1, gam1, nu1, deg1, co1) 
plotfun(x, simpoly)
```

# Sigmoid kernel


```{r sig, eval = F}
k1 <- "sigmoid"
deg1 <- c(3)
simsig <- simfun(x, k1, gam1, nu1, deg1, co1) 
plotfun(x, simsig)
```

# Radial basis function / gaussian kernel


```{r rad}
k1 <- "radial"
deg1 <- c(3)
nu1 <- c(0.01, 0.1, 0.2, 0.4, 0.8)
simrad <- simfun(x, k1, gam1, nu1, deg1, co1) 
plotfun(x, simrad)
```


